# data_acquisition.py - VERS√ÉO CORRIGIDA

import requests
import pandas as pd
import io
import os
from bs4 import BeautifulSoup

# URL de uma p√°gina de terceiros que mant√©m os dados atualizados em formato de tabela
# (Usaremos uma fonte est√°vel para a extra√ß√£o da tabela)
# Alternativa: 'https://www.sorteonline.com.br/mega-sena/resultados'
WEB_SCRAPING_URL = "https://asloterias.com.br/resultados-da-mega-sena-todos-os-sorteios"
DATA_FILE = "megasena_resultados.csv"

def get_latest_results():
    """
    Busca os resultados da Mega Sena fazendo Web Scraping de uma tabela HTML
    e salva os dados em um CSV limpo.
    """
    print(">>> Tentando Web Scraping para adquirir os resultados...")
    
    try:
        # Pandas pode ler tabelas diretamente de uma URL se a estrutura for simples
        # O argumento header=0 define a primeira linha como cabe√ßalho
        tabelas = pd.read_html(WEB_SCRAPING_URL, decimal=',', thousands='.', header=0)
        
        # Na maioria dos sites, a tabela principal de resultados √© a primeira (√≠ndice 0)
        if not tabelas:
            print("‚ùå Nenhuma tabela encontrada na URL.")
            return None
            
        df = tabelas[0]
        
        # --- Limpeza e Sele√ß√£o de Colunas (Se necess√°rio) ---
        
        # Vamos garantir que as colunas de dezenas (D1, D2, ..., D6) estejam presentes
        colunas_dezenas = [col for col in df.columns if col.startswith('Dezena')]
        
        if len(colunas_dezenas) < 6:
             print(f"‚ùå A tabela encontrada n√£o cont√©m as 6 colunas de dezenas esperadas. Colunas encontradas: {df.columns.tolist()}")
             return None

        # Renomeia colunas para simplificar (Ex: Concurso, Data, Dezena1, Dezena2,...)
        df.columns = [
            'Concurso', 'Data', 'Dezena1', 'Dezena2', 'Dezena3', 'Dezena4', 'Dezena5', 'Dezena6', 
            'Ganhadores_Sena', 'Ganhadores_Quina', 'Ganhadores_Quadra', 
            'Valor_Sena', 'Valor_Quina', 'Valor_Quadra', 'Acumulado', 'Estimativa_Prox_Premio'
        ] + df.columns[16:].tolist()

        # Seleciona apenas as colunas relevantes para a an√°lise estat√≠stica
        df = df[['Concurso', 'Data', 'Dezena1', 'Dezena2', 'Dezena3', 'Dezena4', 'Dezena5', 'Dezena6']]
        
        # Remove linhas com valores vazios (NaN) nas dezenas
        df = df.dropna(subset=['Dezena1', 'Dezena2', 'Dezena3', 'Dezena4', 'Dezena5', 'Dezena6'])
        
        # Converte o ID do Concurso para n√∫mero inteiro (importante para ordena√ß√£o)
        df['Concurso'] = pd.to_numeric(df['Concurso'], errors='coerce', downcast='integer')
        
        # Remove linhas onde o Concurso n√£o p√¥de ser convertido (ru√≠do)
        df = df.dropna(subset=['Concurso'])
        
        # Salva o DataFrame limpo em um arquivo local
        df.to_csv(DATA_FILE, index=False, encoding='utf-8')
        
        print(f"‚úÖ Dados de {len(df)} concursos extra√≠dos, limpos e salvos em '{DATA_FILE}'.")
        print("üí° Pr√≥ximo passo: An√°lise Estat√≠stica.")
        return df

    except ValueError as e:
        print(f"‚ùå Erro de Pandas/BeautifulSoup ao ler a tabela: {e}. Verifique se a URL cont√©m tabelas HTML v√°lidas.")
        return None
    except Exception as e:
        print(f"‚ùå Ocorreu um erro inesperado: {e}")
        return None

if __name__ == "__main__":
    get_latest_results()